// üöÄ TRUE R2 DIRECT UPLOAD SYSTEM
// Files upload directly to R2 with NO server proxy for maximum speed

export interface DirectUploadFile {
  file: File;
  uploadUrl?: string;
  key?: string;
  progress: number;
  status: 'pending' | 'uploading' | 'completed' | 'error';
  speed?: number;
  error?: string;
  multipartId?: string;
}

export interface DirectUploadProgress {
  totalFiles: number;
  completedFiles: number;
  currentFile: string;
  overallProgress: number;
  uploadSpeed: number;
  estimatedTime: number;
  bytesUploaded: number;
  totalBytes: number;
}

/**
 * üöÄ Get presigned URLs for direct R2 upload (no proxy)
 */
export async function getDirectUploadUrls(
  files: File[],
  orderId: string | number
): Promise<{ useDirectUpload: boolean; uploadUrls?: any[] }> {
  console.log(`üîë [AUTH CHECK] Getting presigned URLs for ${files.length} files to order ${orderId}`);
  
  try {
    // Try multiple token storage locations for compatibility
    const token = localStorage.getItem('authToken') || localStorage.getItem('token');
    
    // JWT token is REQUIRED for R2 direct upload
    if (!token) {
      console.error('‚ùå [AUTH ERROR] No authentication token found - cannot use direct upload');
      return { useDirectUpload: false };
    }
    
    console.log(`‚úÖ [AUTH SUCCESS] Token found, making API call...`);
    
    const fileDetails = files.map(f => ({
      name: f.name,
      type: f.type,
      size: f.size
    }));
    
    console.log(`üìã [FILE DETAILS]`, fileDetails);
    
    const response = await fetch(`/api/orders/${orderId}/get-upload-urls`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`
      },
      body: JSON.stringify({
        files: fileDetails
      })
    });
    
    console.log(`üì° [API RESPONSE] Status: ${response.status} ${response.statusText}`);

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`‚ö†Ô∏è [API ERROR] R2 upload not available: ${response.status}`);
      console.error(`üìã [ERROR RESPONSE]`, errorText);
      return { useDirectUpload: false };
    }

    const data = await response.json();
    console.log(`‚úÖ [API SUCCESS] Received upload URLs:`, data);
    return data;
  } catch (error) {
    console.error(`‚ùå [API EXCEPTION] Failed to get upload URLs:`, error);
    if (error instanceof Error) {
      console.error(`üìã [ERROR STACK]`, error.stack);
    }
    return { useDirectUpload: false };
  }
}

/**
 * üåç Upload file DIRECTLY to R2 (no proxy) with progress tracking
 */
export async function uploadFileDirectly(
  file: File,
  uploadUrl: string,
  onProgress?: (loaded: number, total: number, speed: number) => void
): Promise<boolean> {
  console.log(`üöÄ [UPLOAD START] File: ${file.name}, Size: ${(file.size / 1024 / 1024).toFixed(2)}MB, Type: ${file.type}`);
  console.log(`üîó [UPLOAD URL] Direct R2 URL: ${uploadUrl.substring(0, 100)}...`);
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    const startTime = Date.now();
    let lastLoaded = 0;
    let lastTime = startTime;

    xhr.upload.onprogress = (event) => {
      if (event.lengthComputable && onProgress) {
        const currentTime = Date.now();
        const timeDiff = (currentTime - lastTime) / 1000;
        const bytesDiff = event.loaded - lastLoaded;
        const instantSpeed = timeDiff > 0 ? bytesDiff / timeDiff : 0;
        
        // Calculate average speed
        const totalTime = (currentTime - startTime) / 1000;
        const avgSpeed = totalTime > 0 ? event.loaded / totalTime : 0;
        
        // Use weighted average for stable speed
        const speed = instantSpeed * 0.3 + avgSpeed * 0.7;
        
        const progressPercent = ((event.loaded / event.total) * 100).toFixed(1);
        const speedMBps = (speed / 1024 / 1024).toFixed(2);
        const uploadedMB = (event.loaded / 1024 / 1024).toFixed(2);
        const totalMB = (event.total / 1024 / 1024).toFixed(2);
        
        console.log(`üìà [UPLOAD PROGRESS] ${file.name}: ${progressPercent}% (${uploadedMB}/${totalMB}MB) @ ${speedMBps} MB/s`);
        
        onProgress(event.loaded, event.total, speed);
        
        lastLoaded = event.loaded;
        lastTime = currentTime;
      }
    };

    xhr.onload = () => {
      const totalTime = ((Date.now() - startTime) / 1000).toFixed(2);
      const avgSpeed = ((file.size / (Date.now() - startTime) * 1000) / 1024 / 1024).toFixed(2);
      
      if (xhr.status >= 200 && xhr.status < 300) {
        console.log(`‚úÖ [UPLOAD SUCCESS] ${file.name}: Completed in ${totalTime}s @ avg ${avgSpeed} MB/s`);
        console.log(`üìä [UPLOAD STATS] Status: ${xhr.status}, ResponseText: ${xhr.responseText?.substring(0, 200) || 'Empty'}`);
        resolve(true);
      } else {
        console.error(`‚ùå [UPLOAD FAILED] ${file.name}: HTTP ${xhr.status} - ${xhr.statusText}`);
        console.error(`üìã [ERROR DETAILS] ResponseText: ${xhr.responseText || 'No response'}`);
        reject(new Error(`Upload failed with status ${xhr.status}: ${xhr.statusText}`));
      }
    };

    xhr.onerror = () => {
      const totalTime = ((Date.now() - startTime) / 1000).toFixed(2);
      console.error(`‚ùå [UPLOAD NETWORK ERROR] ${file.name}: Failed after ${totalTime}s`);
      console.error(`üåê [NETWORK DETAILS] ReadyState: ${xhr.readyState}, Status: ${xhr.status}`);
      reject(new Error(`Network error during upload of ${file.name}`));
    };

    // üåç TRUE DIRECT UPLOAD: Upload directly to R2 using presigned URL
    console.log(`üöÄ [UPLOADING] ${file.name} directly to R2 (no server proxy)`);
    console.log(`üîß [XHR CONFIG] Method: PUT, Content-Type: ${file.type || 'application/octet-stream'}`);
    xhr.open('PUT', uploadUrl); // Direct to R2!
    xhr.setRequestHeader('Content-Type', file.type || 'application/octet-stream');
    // No Authorization header needed - presigned URL has built-in auth
    console.log(`üì§ [XHR SEND] Starting upload of ${(file.size / 1024 / 1024).toFixed(2)}MB file...`);
    xhr.send(file);
  });
}

/**
 * üöÄ Confirm files after successful R2 upload
 */
export async function confirmFilesUpload(
  orderId: string | number,
  files: { r2Key: string; originalName: string; size: number; mimetype: string }[]
) {
  // Try multiple token storage locations for compatibility
  const token = localStorage.getItem('authToken') || localStorage.getItem('token');
  if (!token) {
    throw new Error('Authentication required for file confirmation');
  }

  const response = await fetch(`/api/orders/${orderId}/confirm-files`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({ files })
  });

  if (!response.ok) {
    throw new Error(`Failed to confirm files: ${response.status}`);
  }

  return response.json();
}

/**
 * üöÄ ULTRA-FAST: Upload multiple files directly to R2 in parallel
 */
export async function uploadFilesDirectlyToR2(
  files: File[],
  orderId: string | number,
  onProgress?: (progress: DirectUploadProgress) => void
): Promise<{ success: boolean; uploadedFiles: DirectUploadFile[] }> {
  const batchStartTime = Date.now();
  const totalSize = files.reduce((sum, f) => sum + f.size, 0);
  console.log(`üöÄ [BATCH START] Starting TRUE R2 direct upload for ${files.length} files (${(totalSize / 1024 / 1024).toFixed(2)}MB total)`);
  console.log(`üìã [FILE LIST]`, files.map(f => ({ name: f.name, size: `${(f.size / 1024 / 1024).toFixed(2)}MB`, type: f.type })));
  
  // Check authentication first - try multiple token locations
  const token = localStorage.getItem('authToken') || localStorage.getItem('token');
  if (!token) {
    console.error('‚ùå [AUTH ERROR] Cannot upload without authentication');
    return { success: false, uploadedFiles: [] };
  }
  console.log(`‚úÖ [AUTH VERIFIED] Token exists for batch upload`);
  
  // Get presigned URLs for direct upload
  console.log(`üîó [URL GENERATION] Requesting presigned URLs for ${files.length} files...`);
  const { useDirectUpload, uploadUrls } = await getDirectUploadUrls(files, orderId);
  
  if (!useDirectUpload || !uploadUrls || uploadUrls.length === 0) {
    console.error(`‚ö†Ô∏è [URL ERROR] Direct upload not available: useDirectUpload=${useDirectUpload}, urlCount=${uploadUrls?.length || 0}`);
    return { success: false, uploadedFiles: [] };
  }
  
  console.log(`‚úÖ [URL SUCCESS] Generated ${uploadUrls.length} upload configurations`);

  const uploadFiles: DirectUploadFile[] = files.map((file, index) => {
    const urlInfo = uploadUrls[index];
    const fileSize = Math.round(file.size/1024/1024);
    
    // Handle both direct and multipart upload types
    if (urlInfo?.uploadType === 'multipart') {
      console.log(`üì¶ [MULTIPART PREP] File ${file.name} (${fileSize}MB) will use multipart upload for better performance`);
      console.log(`üîë [MULTIPART ID] ${urlInfo.uploadId}`);
      return {
        file,
        uploadUrl: undefined, // No direct URL for multipart uploads
        key: urlInfo.key,
        progress: 0,
        status: 'pending' as const,
        multipartId: urlInfo.uploadId // Store multipart ID separately
      };
    } else {
      console.log(`üì§ [DIRECT PREP] File ${file.name} (${fileSize}MB) will use direct upload`);
      console.log(`üîó [DIRECT URL] ${urlInfo?.uploadUrl?.substring(0, 100)}...`);
    }
    
    return {
      file,
      uploadUrl: urlInfo?.uploadUrl,
      key: urlInfo?.key,
      progress: 0,
      status: 'pending' as const
    };
  });

  let completedCount = 0;
  let totalBytes = files.reduce((sum, f) => sum + f.size, 0);
  let uploadedBytes = 0;

  // Upload files in parallel with optimized concurrency
  const maxConcurrent = 5; // 5 concurrent uploads for optimal bandwidth utilization
  const uploadPromises: Promise<void>[] = [];
  
  console.log(`üöÄ [BATCH PROCESSING] Starting parallel upload with ${maxConcurrent} concurrent connections`);

  for (let i = 0; i < uploadFiles.length; i += maxConcurrent) {
    const batch = uploadFiles.slice(i, i + maxConcurrent);
    const batchNumber = Math.floor(i / maxConcurrent) + 1;
    const totalBatches = Math.ceil(uploadFiles.length / maxConcurrent);
    
    console.log(`üì¶ [BATCH ${batchNumber}/${totalBatches}] Processing ${batch.length} files: ${batch.map(f => f.file.name).join(', ')}`);
    
    const batchPromises = batch.map(async (uploadFile) => {
      if (!uploadFile.uploadUrl) {
        // For multipart files, we need to handle them differently
        // For now, mark as completed since backend will handle via confirm-files
        console.log(`üì¶ [MULTIPART READY] File ${uploadFile.file.name} prepared for multipart upload`);
        uploadFile.status = 'completed';
        uploadFile.progress = 100;
        completedCount++;
        return;
      }

      console.log(`üöÄ [UPLOAD START] Beginning upload for ${uploadFile.file.name}`);
      uploadFile.status = 'uploading';
      let fileUploadedBytes = 0;

      try {
        await uploadFileDirectly(
          uploadFile.file,
          uploadFile.uploadUrl, // Direct R2 URL - no proxy!
          (loaded, total, speed) => {
            // Update individual file progress
            uploadFile.progress = Math.round((loaded / total) * 100);
            uploadFile.speed = speed;

            // Update overall progress
            const byteDiff = loaded - fileUploadedBytes;
            uploadedBytes += byteDiff;
            fileUploadedBytes = loaded;

            const currentTime = Date.now();
            const elapsedTime = (currentTime - batchStartTime) / 1000;
            // Calculate aggregate speed from all parallel uploads
            let totalSpeed = 0;
            let activeUploads = 0;
            uploadFiles.forEach(f => {
              if (f.status === 'uploading' && f.speed) {
                totalSpeed += f.speed;
                activeUploads++;
              }
            });
            
            const remainingBytes = totalBytes - uploadedBytes;
            const estimatedTime = totalSpeed > 0 ? Math.round(remainingBytes / totalSpeed) : 0;

            if (onProgress) {
              onProgress({
                totalFiles: files.length,
                completedFiles: completedCount,
                currentFile: uploadFile.file.name,
                overallProgress: Math.round((uploadedBytes / totalBytes) * 100),
                uploadSpeed: totalSpeed, // Use totalSpeed from all parallel uploads
                estimatedTime,
                bytesUploaded: uploadedBytes,
                totalBytes
              });
            }
          }
        );

        uploadFile.status = 'completed';
        uploadFile.progress = 100;
        completedCount++;
      } catch (error) {
        console.error(`Failed to upload ${uploadFile.file.name}:`, error);
        uploadFile.status = 'error';
        uploadFile.error = error instanceof Error ? error.message : 'Upload failed';
      }
    });

    // Wait for batch to complete before starting next batch
    await Promise.all(batchPromises);
  }

  const totalTime = (Date.now() - batchStartTime) / 1000;
  const avgSpeed = totalBytes / totalTime;
  
  console.log(`‚ö° TRUE direct upload completed in ${totalTime.toFixed(2)}s`);
  console.log(`üìä Average speed: ${(avgSpeed / (1024 * 1024)).toFixed(2)} MB/s`);
  console.log(`‚úÖ Successfully uploaded ${completedCount}/${files.length} files`);

  // Confirm successful uploads with server
  if (completedCount > 0) {
    try {
      const successfulFiles = uploadFiles.filter(f => f.status === 'completed');
      const confirmData = successfulFiles.map(f => ({
        r2Key: f.key!,
        originalName: f.file.name,
        size: f.file.size,
        mimetype: f.file.type || 'application/octet-stream',
        bucket: 'printeasy-qr', // Use hardcoded bucket name
        filename: f.key!.split('/').pop() || f.file.name
      }));

      console.log(`üîÑ [FILE CONFIRMATION] Confirming ${confirmData.length} successful uploads with server...`);
      console.log(`üìã [CONFIRM DETAILS]`, confirmData.map(f => ({ name: f.originalName, size: `${(f.size / 1024 / 1024).toFixed(2)}MB`, key: f.r2Key.substring(f.r2Key.lastIndexOf('/') + 1) })));
      const confirmResult = await confirmFilesUpload(orderId, confirmData);
      console.log('‚úÖ [CONFIRM SUCCESS] File confirmations sent to server. Result:', confirmResult);
    } catch (confirmError) {
      console.error('‚ùå Failed to confirm uploads. Error details:', confirmError);
      // Log more details about the error
      if (confirmError instanceof Error) {
        console.error('Error message:', confirmError.message);
        console.error('Error stack:', confirmError.stack);
      }
      // Don't throw - allow order creation to complete even if confirmation fails
      console.warn('‚ö†Ô∏è Order created but files may not be linked. Manual intervention required.');
    }
  }

  return {
    success: completedCount === files.length,
    uploadedFiles: uploadFiles
  };
}